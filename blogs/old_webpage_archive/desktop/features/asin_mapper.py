"""
ASIN Intent Mapper Feature

Automatically detects ASIN searches, looks them up via API,
categorizes competitors vs your products, generates negative keywords.
"""

import streamlit as st
import pandas as pd
import re
from typing import Dict, Any
from features._base import BaseFeature
from core.data_loader import SmartMapper, load_uploaded_file, safe_numeric
from api.rainforest_client import RainforestClient
from utils.validators import validate_search_term_report
from ui.components import metric_card

class ASINMapperModule(BaseFeature):
    """ASIN Intent Mapping and Competitor Detection."""
    
    def __init__(self):
        super().__init__()
        self.asin_pattern = r'\b[bB]0[a-zA-Z0-9]{8}\b'
        
    def load_config(self) -> Dict[str, Any]:
        """Load ASIN mapper configuration."""
        config = {
            'api_key': '',
            'user_brands': ['s2c'],
            'user_asins': [],
            'min_wasted_spend': 5.0,
            'min_clicks': 3
        }
        
        try:
            if hasattr(st, 'secrets'):
                # API Key (try both cases)
                try:
                    key = st.secrets["RAINFOREST_API_KEY"]
                    if key and key != "your_key_here":
                        config['api_key'] = key
                except KeyError:
                    try:
                        key = st.secrets["rainforest_api_key"]
                        if key and key != "your_key_here":
                            config['api_key'] = key
                    except KeyError:
                        pass
                
                # Brands
                try:
                    config['user_brands'] = list(st.secrets["USER_BRANDS"])
                except KeyError:
                    pass
                
                # ASINs
                try:
                    config['user_asins'] = list(st.secrets["USER_ASINS"])
                except KeyError:
                    pass
        except Exception:
            pass  # Will use defaults
            
        return config
    
    def run(self):
        """Override BaseFeature.run to have full control over the flow."""
        self.render_ui()

    def render_ui(self):
        """Render the ASIN Mapper UI."""
        # Icons
        icon_color = "#8F8CA3"
        shield_icon = f'<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="{icon_color}" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="vertical-align: middle; margin-right: 8px;"><path d="M12 22s8-4 8-10V5l-8-3-8 3v7c0 6 8 10 8 10z"></path></svg>'
        
        def tab_header(label, icon_html):
            st.markdown(f"""
            <div style="background: linear-gradient(135deg, rgba(91, 85, 111, 0.1) 0%, rgba(91, 85, 111, 0.05) 100%); 
                        border: 1px solid rgba(124, 58, 237, 0.2); 
                        border-radius: 8px; 
                        padding: 12px 16px; 
                        margin-bottom: 20px;
                        display: flex; 
                        align-items: center; 
                        gap: 10px;">
                {icon_html}
                <span style="color: #F5F5F7; font-size: 1rem; font-weight: 700; text-transform: uppercase; letter-spacing: 1px;">{label}</span>
            </div>
            """, unsafe_allow_html=True)

        tab_header("Competitor Discovery", shield_icon)
        st.markdown("""
        <div style="background: rgba(91, 85, 111, 0.05); border-left: 4px solid #5B556F; padding: 12px 20px; border-radius: 0 8px 8px 0; margin-bottom: 24px;">
            <p style="color: #B6B4C2; font-size: 0.95rem; margin: 0;">
                Automatically identify competitor ASINs, detect wasted spend on your own listings, and discover negative targeting opportunities.
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        # Check if data loaded in Data Hub
        from core.data_hub import DataHub
        hub = DataHub()
        
        data_from_hub = False
        if hub.is_loaded('search_term_report'):
            # st.success("‚úÖ Using data from Data Hub") # Removed as per user request
            self.data = hub.get_data('search_term_report')
            data_from_hub = True
            
            # Load advertised products if available
            if hub.is_loaded('advertised_product_report'):
                adv_data = hub.get_data('advertised_product_report')
                if adv_data is not None and 'ASIN' in adv_data.columns:
                    user_asins = adv_data['ASIN'].dropna().unique().tolist()
                    self.config['user_asins'] = user_asins
                    # st.info(f"‚úÖ Loaded {len(user_asins)} of your ASINs from Data Hub")
        

        
        # Get thresholds from shared Optimizer widget session state or config or defaults
        # Priority: Widget keys > optimizer_config > hardcoded defaults
        # This ensures ASIN Mapper uses the LATEST values set by the user in the Optimizer sidebar
        universal_clicks = st.session_state.get(
            'opt_neg_clicks_threshold', 
            st.session_state.get('optimizer_config', {}).get('NEGATIVE_CLICKS_THRESHOLD', 10)
        )
        universal_spend = st.session_state.get(
            'opt_neg_spend_threshold', 
            st.session_state.get('optimizer_config', {}).get('NEGATIVE_SPEND_THRESHOLD', 10.0)
        )
        
        self.config['min_clicks'] = universal_clicks
        self.config['min_wasted_spend'] = universal_spend
        self.config['bleeder_clicks'] = universal_clicks
        self.config['bleeder_spend'] = universal_spend
        
        # UI Controls for thresholds removed - now fully managed by Optimization Hub settings
        
        # Ensure Data is present (Strict Data Hub dependency)
        if not hasattr(self, 'data') or self.data is None:
             st.warning("‚ö†Ô∏è No Search Term Report found.")
             st.info("Please go to **Data Hub** (in sidebar) and upload your Search Term Report.")
             return

        # Execution Logic
        if hasattr(self, 'data') and self.data is not None:
            valid, msg = self.validate_data(self.data)
            if not valid:
                st.error(f"‚ùå Data Validation Error: {msg}")
                return
            
            # Start Analysis automatically or via button (using button for better control)
            # Check for existing results
            if 'latest_asin_analysis' in st.session_state:
                results = st.session_state['latest_asin_analysis']
            else:
                results = None
            
        if st.button("üöÄ Analyze Search Terms for ASIN Intent", type="primary", use_container_width=True):
            with st.spinner("Classifying ASINs..."):
                results = self.analyze(self.data)
                st.session_state['latest_asin_analysis'] = results
        
        # Display results if available
        if results:
            st.markdown("<br>", unsafe_allow_html=True)
            self.display_results(results)
    
    def validate_data(self, data: pd.DataFrame) -> tuple[bool, str]:
        """Validate search term report data."""
        # Check if columns are already in standard format (from Data Hub)
        required = ['Customer Search Term', 'Impressions', 'Clicks', 'Spend', 'Orders']
        
        # First check if already renamed (from Data Hub)
        already_standard = all(col in data.columns for col in ['Customer Search Term', 'Impressions', 'Clicks', 'Spend'])
        
        if already_standard:
            # Data from Data Hub - already renamed
            missing = [r for r in required if r not in data.columns]
            if missing:
                return False, f"Missing required columns: {', '.join(missing)}"
            return True, ""
        
        # Original format - need to map
        col_map = SmartMapper.map_columns(data)
        missing = [r for r in required if r not in col_map]
        
        if missing:
            return False, f"Missing required columns: {', '.join(missing)}"
        
        return True, ""
    
    def analyze(self, data: pd.DataFrame) -> Dict[str, Any]:
        """Core ASIN analysis logic - PURE DATA PROCESSING (No UI)."""
        # Check if columns already in standard format (from Data Hub)
        if 'Customer Search Term' in data.columns:
            term_col = 'Customer Search Term'
            imp_col = 'Impressions'
            clicks_col = 'Clicks'
            spend_col = 'Spend'
            orders_col = 'Orders' if 'Orders' in data.columns else None
        else:
            col_map = SmartMapper.map_columns(data)
            term_col = col_map['Customer Search Term']
            imp_col = col_map['Impressions']
            clicks_col = col_map['Clicks']
            spend_col = col_map['Spend']
            orders_col = col_map.get('Orders')
        
        # Step 1: Detect ASIN searches
        data['is_asin_search'] = data[term_col].astype(str).str.contains(self.asin_pattern, regex=True, na=False)
        asin_searches = data[data['is_asin_search']].copy()
        
        if asin_searches.empty:
            return {'asins_found': 0}
        
        # Ensure we have campaign/ad group columns
        camp_col = 'Campaign Name' if 'Campaign Name' in asin_searches.columns else 'Campaign'
        ag_col = 'Ad Group Name' if 'Ad Group Name' in asin_searches.columns else 'AdGroup'
        
        # Campaign/AdGroup IDs if available
        has_ids = 'CampaignId' in asin_searches.columns and 'AdGroupId' in asin_searches.columns
        
        # Aggregate by ASIN + Campaign + Ad Group (NOT globally!)
        group_cols = [term_col, camp_col, ag_col]
        agg_dict = {
            imp_col: 'sum',
            clicks_col: 'sum',
            spend_col: lambda x: safe_numeric(x).sum(),
        }
        if orders_col and orders_col in asin_searches.columns:
            agg_dict[orders_col] = 'sum'
        else:
            asin_searches['Orders'] = 0
            agg_dict['Orders'] = 'sum'
        
        # Add campaign/ad group IDs if available
        if has_ids:
            agg_dict['CampaignId'] = 'first'
            agg_dict['AdGroupId'] = 'first'
        
        asin_agg = asin_searches.groupby(group_cols).agg(agg_dict).reset_index()
        asin_agg.columns = ['asin', 'Campaign Name', 'Ad Group Name', 'impressions', 'clicks', 'spend', 'orders'] + (['CampaignId', 'AdGroupId'] if has_ids else [])
        asin_agg['converting'] = asin_agg['orders'] > 0
        
        # Global metrics (for summary display)
        total_asins = asin_agg['asin'].nunique()
        non_converting = asin_agg[~asin_agg['converting']]
        
        # Step 2: Prioritize for lookup (per campaign/ad group, not global!)
        # Filter to bleeders (meets threshold at campaign/ad-group level)
        high_priority = non_converting[
            (non_converting['clicks'] >= self.config['min_clicks']) &
            (non_converting['spend'] >= self.config['min_wasted_spend'])
        ].nlargest(30, 'spend')
        
        return {
            'asins_found': total_asins,
            'high_priority': high_priority,  # Now includes Campaign + Ad Group
            'asin_summary': asin_agg,  # Per-campaign breakdown
            'non_converting_count': len(non_converting),
            'converting_count': len(asin_agg[asin_agg['converting']]),
            'total_wasted': non_converting['spend'].sum()
        }


    def display_results(self, results: Dict[str, Any]):
        """Display ASIN analysis results - HANDLES ALL UI & API CALLS."""
        
        # 1. Basic Metrics
        if results.get('asins_found', 0) == 0:
            st.warning("No ASIN searches found in this report")
            return

        col1, col2, col3, col4 = st.columns(4)
        with col1: metric_card("Total ASINs", f"{results['asins_found']:,}", "layers")
        with col2: metric_card("Converting", f"{results.get('converting_count', 0):,}", "check")
        with col3: metric_card("Non-Converting", f"{results.get('non_converting_count', 0):,}", "x_circle")
        with col4: metric_card("Wasted Spend", f"AED {results.get('total_wasted', 0):,.2f}", "trending_up")
        
        # 2. High Priority List
        high_priority = results.get('high_priority', pd.DataFrame())
        
        icon_color = "#8F8CA3"
        search_icon = f'<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="{icon_color}" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="vertical-align: middle; margin-right: 8px;"><circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line></svg>'
        
        st.markdown(f"""
        <div style="margin-top: 30px; margin-bottom: 15px; display: flex; align-items: center; gap: 8px;">
            {search_icon}
            <span style="color: #F5F5F7; font-size: 1.1rem; font-weight: 600;">High-Priority ASIN Candidates ({len(high_priority)})</span>
        </div>
        """, unsafe_allow_html=True)
        
        if high_priority.empty:
            st.info("No high-priority non-converting ASINs found based on current thresholds.")
            return
        
        st.dataframe(high_priority[['asin', 'impressions', 'clicks', 'spend']], use_container_width=True)
        
        # 3. API Lookup Logic (The Action)
        # Check if we already have API results (persisted in results dict)
        if 'competitors' in results:
            self._display_enriched_results(results)
        else:


            # ACTUAL REPLACEMENT LOGIC
            # I will insert the Clear Cache button right before the Lookup button check
            
            if st.button("üóëÔ∏è Force Refresh / Clear Cache", key="clear_cache_btn", type="secondary", use_container_width=True):
                try:
                    import os, time
                    if os.path.exists("data/asin_cache.db"):
                        os.remove("data/asin_cache.db")
                        st.toast("Cache cleared! fetching fresh data...", icon="üßπ")
                        time.sleep(1)
                    else:
                        st.toast("Cache was already clean", icon="‚ú®")
                except Exception as e:
                    st.error(f"Could not clear cache: {e}")

            if st.button(f"üöÄ Enrich {len(high_priority)} ASINs via Rainforest API", key="asin_lookup_trigger_v2", type="primary", use_container_width=True):
                
                # Fresh secrets read (bypass cached config)
                api_key = None
                try:
                    api_key = st.secrets["RAINFOREST_API_KEY"]
                except:
                    try:
                        api_key = st.secrets["rainforest_api_key"]
                    except:
                        pass
                
                if not api_key:
                    st.error("‚ùå Rainforest API key not found in secrets.toml")
                    st.info("Add `RAINFOREST_API_KEY = 'your_key'` to `.streamlit/secrets.toml`")
                    return
                
                with st.spinner("Classifying ASINs and retrieving product details..."):
                    client = RainforestClient(api_key)
                    asin_details = []
                    progress = st.progress(0)
                    total = len(high_priority)
                    
                    for i, (idx, row) in enumerate(high_priority.iterrows()):
                        details = client.lookup_asin(row['asin'])
                        
                        # DEBUG: Show what API returned
                        print(f"API Response for {row['asin']}: status={details.get('status', 'unknown')}, brand={details.get('brand', 'MISSING')}, title={details.get('title', 'MISSING')[:50] if details.get('title') else 'MISSING'}")
                        
                        # Merge original stats AND campaign/ad-group info
                        details['original_impressions'] = row['impressions']
                        details['original_clicks'] = row['clicks']
                        details['original_spend'] = row['spend']
                        details['Campaign Name'] = row.get('Campaign Name', '')
                        details['Ad Group Name'] = row.get('Ad Group Name', '')
                        
                        # Preserve IDs if available
                        if 'CampaignId' in row:
                            details['CampaignId'] = row['CampaignId']
                        if 'AdGroupId' in row:
                            details['AdGroupId'] = row['AdGroupId']
                        
                        asin_details.append(details)
                        progress.progress((i + 1) / total)
                    
                    details_df = pd.DataFrame(asin_details)
                    
                    # Categorize (competitor vs yours)
                    details_df['category'] = details_df.apply(lambda x: self._categorize_asin(x), axis=1)
                    
                    # Split
                    competitors = details_df[details_df['category'] == 'COMPETITOR']
                    your_products = details_df[details_df['category'] == 'YOUR_PRODUCT']
                    
                    # Flagging
                    flagged = competitors[
                        (competitors['original_clicks'] >= self.config['bleeder_clicks']) &
                        (competitors['original_spend'] >= self.config['bleeder_spend'])
                    ]
                    
                    # Update Result Dict
                    results['asin_details'] = details_df
                    results['competitors'] = competitors
                    results['your_products'] = your_products
                    results['flagged_for_negation'] = flagged
                    
                    # Format for Optimizer integration
                    results['optimizer_negatives'] = self._format_for_optimizer(flagged, competitors, your_products)
                    
                    # DEBUG: Confirm integration data
                    print(f"üîç ASIN Mapper ‚Üí Optimizer: {len(results['optimizer_negatives']['competitor_asins'])} competitor ASINs, {len(results['optimizer_negatives']['your_products_review'])} your products")
                    
                    # Persist Update
                    st.session_state['latest_asin_analysis'] = results
                    st.rerun()  # Rerun to show Enriched View

    def _display_enriched_results(self, results):
        """Helper to show the advanced view (Competitors, Diagnostics) AFTER API lookup."""
        st.markdown("""
        <div style="background: rgba(16, 185, 129, 0.1); border: 1px solid rgba(16, 185, 129, 0.2); padding: 12px 20px; border-radius: 8px; margin-bottom: 24px; color: #10B981; font-weight: 600; display: flex; align-items: center; gap: 10px;">
            <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path><polyline points="22 4 12 14.01 9 11.01"></polyline></svg>
            API Lookup Complete & Brand Data Synchronized
        </div>
        """, unsafe_allow_html=True)
        
        # Download Button with Brand Style
        output = self.generate_output(results)
        st.download_button(
            label="üì• Export Full Enrichment Report (.xlsx)",
            data=output,
            file_name="asin_analysis_results.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            key="asin_download_btn",
            type="primary",
            use_container_width=True
        )
        st.markdown("<br>", unsafe_allow_html=True)
        
        competitors = results['competitors']
        your_products = results['your_products']
        flagged = results['flagged_for_negation']
        
        # Metrics
        col1, col2, col3 = st.columns(3)
        with col1: metric_card("Competitors", len(competitors), "layers")
        with col2: metric_card("Your Products", len(your_products), "check")
        with col3: metric_card("Negation Flagged", len(flagged), "shield")
        
        # 1. Flagged Competitors
        icon_color = "#8F8CA3"
        shield_icon = f'<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="{icon_color}" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="vertical-align: middle; margin-right: 8px;"><path d="M12 22s8-4 8-10V5l-8-3-8 3v7c0 6 8 10 8 10z"></path></svg>'
        bolt_icon = f'<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="{icon_color}" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="vertical-align: middle; margin-right: 8px;"><polygon points="13 2 3 14 12 14 11 22 21 10 12 10 13 2"></polygon></svg>'
        search_alt_icon = f'<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="{icon_color}" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="vertical-align: middle; margin-right: 8px;"><circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line></svg>'

        if not flagged.empty:
            st.divider()
            st.markdown(f"#### {shield_icon}Competitors Recommended for Negation", unsafe_allow_html=True)
            st.markdown(f"""
            <div style="background: rgba(124, 58, 237, 0.05); border-left: 4px solid #7C3AED; padding: 12px 20px; border-radius: 0 8px 8px 0; margin-bottom: 20px;">
                <p style="color: #F5F5F7; font-size: 0.95rem; margin: 0;">
                    <strong>Recommendation</strong>: These {len(flagged)} competitor products are showing significant wasted spend without conversions. Monthly savings: <strong>AED {flagged['original_spend'].sum():.2f}</strong>.
                </p>
            </div>
            """, unsafe_allow_html=True)
            
            flagged_display = flagged.copy()
            for col in ['asin', 'brand', 'title', 'original_clicks', 'original_spend']:
                if col not in flagged_display.columns:
                    flagged_display[col] = 'N/A'
            flagged_display = flagged_display[['asin', 'brand', 'title', 'original_clicks', 'original_spend']].copy()
            flagged_display.columns = ['ASIN', 'Brand', 'Product', 'Clicks', 'Wasted Spend']
            flagged_display = flagged_display.fillna('N/A')
            st.dataframe(flagged_display, use_container_width=True)

        # 2. Your Non-Converting Products (Diagnostics)
        if not your_products.empty:
            st.divider()
            st.markdown(f"#### {bolt_icon}Listing Diagnostics (Your Products)", unsafe_allow_html=True)
            st.markdown(f"""
            <div style="background: rgba(245, 158, 11, 0.05); border-left: 4px solid #F59E0B; padding: 12px 20px; border-radius: 0 8px 8px 0; margin-bottom: 20px;">
                <p style="color: #F5F5F7; font-size: 0.95rem; margin: 0;">
                    <strong>Alert</strong>: Found {len(your_products)} of your own products that are receiving traffic but failing to convert. Review listings for stock or price issues.
                </p>
            </div>
            """, unsafe_allow_html=True)
            
            for idx, product in your_products.iterrows():
                with st.expander(f"üîç {product['asin']} - {product.get('brand', 'N/A')} ({product['original_clicks']} clicks, AED {product['original_spend']:.2f} wasted)", expanded=False):
                    self._render_diagnostic_card(product)

        # 3. All Competitors
        if not competitors.empty:
            st.divider()
            st.markdown(f"#### {search_alt_icon}Consolidated Competitor Footprint", unsafe_allow_html=True)
            
            if 'brand' in competitors.columns:
                comp_summary = competitors.groupby('brand').agg({'asin': 'count', 'original_spend': 'sum'}).sort_values('original_spend', ascending=False)
                comp_summary.columns = ['Count', 'Total Wasted Spend']
                st.dataframe(comp_summary, use_container_width=True)
            else:
                st.dataframe(competitors, use_container_width=True)

    def _render_diagnostic_card(self, product):
        """Render diagnostic details for a single product."""
        # Product info
        col1, col2 = st.columns([2, 1])
        with col1:
            st.markdown(f"**Product:** {str(product.get('title', 'N/A'))[:100]}...")
            st.markdown(f"**Brand:** {product.get('brand', 'N/A')}")
        with col2:
            metric_card("Wasted Spend", f"AED {product['original_spend']:.2f}")

        # Diagnostics Logic (Simplified for this patch to fit token limits, but robust enough)
        issues = []
        availability = str(product.get('availability', '')).lower()
        if 'out of stock' in availability: issues.append("‚ùå OUT OF STOCK")
        
        rating = product.get('rating')
        if rating and float(rating) < 3.5: issues.append(f"‚ùå LOW RATING: {rating}‚òÖ")
        
        st.markdown("**Issues Found:**")
        if issues:
            for i in issues: st.markdown(f"- {i}")
        else:
            st.success("No critical listing issues detected.")
    
    def _categorize_asin(self, row: pd.Series) -> str:
        """Categorize ASIN as competitor, your product, or wrong category."""
        asin = str(row.get('asin', '')).upper()
        brand = str(row.get('brand', '')).lower()
        seller = str(row.get('seller', '')).lower()
        
        # Check if it's in user's ASIN list (most reliable)
        if 'user_asins' in self.config:
            for user_asin in self.config['user_asins']:
                if user_asin.upper() == asin:
                    return 'YOUR_PRODUCT'
        
        # Check if it's user's product by brand/seller
        for user_brand in self.config.get('user_brands', []):
            if user_brand.lower() in brand or user_brand.lower() in seller:
                return 'YOUR_PRODUCT'
        
        # Otherwise competitor
        return 'COMPETITOR'
    
    def _format_for_optimizer(self, flagged_competitors: pd.DataFrame, all_competitors: pd.DataFrame, your_products: pd.DataFrame) -> dict:
        """Format ASIN data for Optimizer integration."""
        optimizer_data = {
            'competitor_asins': [],
            'your_products_review': []
        }
        
        # Format flagged competitors (auto-negate recommended)
        if not flagged_competitors.empty:
            for _, row in flagged_competitors.iterrows():
                optimizer_data['competitor_asins'].append({
                    "Type": "ASIN Mapper - Competitor",
                    "Campaign Name": row.get("Campaign Name", ""),
                    "Ad Group Name": row.get("Ad Group Name", ""),
                    "Term": row['asin'],
                    "Is_ASIN": True,
                    "Clicks": int(row.get('original_clicks', 0)),
                    "Spend": float(row.get('original_spend', 0)),
                    "CampaignId": row.get("CampaignId", ""),
                    "AdGroupId": row.get("AdGroupId", ""),
                    "Brand": row.get("brand", "Unknown"),
                    "Product": str(row.get("title", "Unknown"))[:50]
                })
        
        # Format your products (manual review required)
        if not your_products.empty:
            for _, row in your_products.iterrows():
                spend = float(row.get('original_spend', 0))
                clicks = int(row.get('original_clicks', 0))
                
                # Recommendation based on spend
                if spend > 50:
                    recommendation = "‚ö†Ô∏è High waste - review urgently"
                elif clicks > 30:
                    recommendation = "‚ö†Ô∏è Many clicks, 0 orders - likely wrong"
                else:
                    recommendation = "‚ÑπÔ∏è Low volume - monitor"
                
                optimizer_data['your_products_review'].append({
                    "Type": "ASIN Mapper - Your Product",
                    "Campaign Name": row.get("Campaign Name", ""),
                    "Ad Group Name": row.get("Ad Group Name", ""),
                    "Term": row['asin'],
                    "Is_ASIN": True,
                    "Clicks": clicks,
                    "Spend": spend,
                    "CampaignId": row.get("CampaignId", ""),
                    "AdGroupId": row.get("AdGroupId", ""),
                    "Brand": row.get("brand", "Your Brand"),
                    "Product": str(row.get("title", "Unknown"))[:50],
                    "Recommendation": recommendation
                })
        
        return optimizer_data
    
    def generate_output(self, results: Dict[str, Any]) -> bytes:
        """Generate Excel output with negative keywords."""
        from io import BytesIO
        import xlsxwriter
        
        output = BytesIO()
        
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            # Summary sheet
            if 'asin_summary' in results:
                results['asin_summary'].to_excel(writer, sheet_name='All ASINs', index=False)
            
            # Flagged for negation (PRIORITY SHEET - this is what to upload!)
            if 'flagged_for_negation' in results and not results['flagged_for_negation'].empty:
                flagged = results['flagged_for_negation'].copy()
                
                # Ensure all required columns exist
                for col in ['asin', 'brand', 'title', 'original_clicks', 'original_spend']:
                    if col not in flagged.columns:
                        flagged[col] = 'N/A'
                
                # Select and rename
                flagged_summary = flagged[['asin', 'brand', 'title', 'original_clicks', 'original_spend']].copy()
                flagged_summary.columns = ['ASIN', 'Brand', 'Product Title', 'Clicks', 'Wasted Spend']
                flagged_summary = flagged_summary.fillna('N/A')
                
                flagged_summary.to_excel(writer, sheet_name='Flagged for Negation', index=False)
            
            # Your non-converting products with diagnostics
            if 'your_products' in results and not results['your_products'].empty:
                your_products = results['your_products'].copy()
                
                # Ensure all required columns exist
                for col in ['asin', 'title', 'brand', 'original_spend', 'original_clicks']:
                    if col not in your_products.columns:
                        your_products[col] = 'N/A'
                
                # Select and rename
                your_export = your_products[['asin', 'title', 'brand', 'original_spend', 'original_clicks']].copy()
                your_export.columns = ['ASIN', 'Product Title', 'Brand', 'Wasted Spend', 'Clicks']
                your_export = your_export.fillna('N/A')
                your_export.to_excel(writer, sheet_name='Your Products', index=False)
                
                # Diagnostics sheet
                diagnostics_data = []
                for _, product in your_products.iterrows():
                    # Run diagnostics
                    issues = []
                    priority = "LOW"
                    
                    # Stock check
                    availability = str(product.get('availability', '')).lower()
                    if 'out of stock' in availability or 'unavailable' in availability:
                        issues.append("OUT OF STOCK")
                        priority = "HIGH"
                    
                    # Rating check
                    rating = product.get('rating')
                    if rating:
                        try:
                            rating_float = float(rating)
                            if rating_float < 3.5:
                                issues.append(f"LOW RATING: {rating_float}‚òÖ")
                                priority = "HIGH" if priority != "HIGH" else priority
                            elif rating_float < 4.0:
                                issues.append(f"BELOW 4.0: {rating_float}‚òÖ")
                                priority = "MEDIUM" if priority == "LOW" else priority
                        except:
                            pass
                    
                    # Review count check
                    reviews_count = product.get('reviews_count')
                    if reviews_count:
                        try:
                            reviews_int = int(reviews_count)
                            if reviews_int < 10:
                                issues.append(f"LOW REVIEWS: {reviews_int}")
                                priority = "MEDIUM" if priority == "LOW" else priority
                        except:
                            pass
                    
                    diagnostics_data.append({
                        'ASIN': product['asin'],
                        'Product': str(product.get('title', ''))[:50],
                        'Priority': priority,
                        'Rating': product.get('rating', 'N/A'),
                        'Reviews': product.get('reviews_count', 'N/A'),
                        'Stock Status': product.get('availability', 'N/A')[:30],
                        'Price': f"{product.get('currency', 'AED')} {product.get('price', 'N/A')}",
                        'Issues': ' | '.join(issues) if issues else 'None detected',
                        'Wasted Spend': product.get('original_spend', 0),
                        'Clicks': product.get('original_clicks', 0),
                        'Listing URL': product.get('product_url', '')
                    })
                
                if diagnostics_data:
                    diagnostics_df = pd.DataFrame(diagnostics_data)
                    diagnostics_df.to_excel(writer, sheet_name='Diagnostics', index=False)
            
            # All competitor details (reference)
            if 'competitors' in results and not results['competitors'].empty:
                competitors = results['competitors'].copy()
                
                # Ensure all required columns exist
                for col in ['asin', 'brand', 'title', 'original_clicks', 'original_spend']:
                    if col not in competitors.columns:
                        competitors[col] = 'N/A'
                
                # Select and rename
                comp_export = competitors[['asin', 'brand', 'title', 'original_clicks', 'original_spend']].copy()
                comp_export.columns = ['ASIN', 'Brand', 'Product Title', 'Clicks', 'Wasted Spend']
                comp_export = comp_export.fillna('N/A')
                comp_export.to_excel(writer, sheet_name='All Competitors', index=False)
            
            # Amazon-ready negative keywords (FLAGGED ONLY)
            if 'flagged_for_negation' in results and not results['flagged_for_negation'].empty:
                negatives = results['flagged_for_negation'][['asin']].copy()
                
                # Format for Amazon Negative Product Targeting
                negatives['Product'] = 'Sponsored Products'
                negatives['Entity'] = 'Negative Product Targeting'
                negatives['Operation'] = 'Create'
                negatives['Campaign ID'] = ''
                negatives['Ad Group ID'] = ''
                negatives['Campaign Name'] = ''  # User fills this
                negatives['Ad Group Name'] = ''  # User fills this
                
                # Format ASIN with quotes
                negatives['Product Targeting Expression'] = negatives['asin'].apply(lambda x: f'ASIN="{x.upper()}"')
                negatives['Match Type'] = 'Negative Exact'
                
                # Reorder columns for Amazon format
                negatives = negatives[[
                    'Product', 'Entity', 'Operation', 
                    'Campaign ID', 'Ad Group ID', 
                    'Campaign Name', 'Ad Group Name', 
                    'Product Targeting Expression', 'Match Type'
                ]]
                
                negatives.to_excel(writer, sheet_name='Negative Keywords Upload', index=False)
        
        return output.getvalue()
